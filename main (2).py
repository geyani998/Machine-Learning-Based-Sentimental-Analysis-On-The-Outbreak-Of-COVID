# -*- coding: utf-8 -*-
"""UROP-SA-NLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HUbdTVUJbURJobbEZTDOcAeVgWG9tTA9

**DATASET**
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
path = "/content/drive/MyDrive/ML CSV files/Sentimental analysis of COVID-19 Tweets.csv"
dataset = pd.read_csv(path)
dataset.head()

dataset.shape

"""**DATA PREPROCESSING**"""

dataset.shape

print(dataset.sentiment.value_counts())
dataset.drop_duplicates(inplace=True)

pip install langdetect

from textblob import TextBlob
import sys
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import os
import nltk
import re
import string
import seaborn as sns
from PIL import Image
from nltk.sentiment.vader import SentimentIntensityAnalyzer
from nltk.stem import SnowballStemmer
from nltk.sentiment.vader import SentimentIntensityAnalyzer
from sklearn.feature_extraction.text import CountVectorizer

#Removing RT, Punctuation, special characters... etc
remove_rt = lambda x: re.sub('RT @\w+: '," ",x)
rt = lambda x: re.sub("(@[A-Za-z0-9]+)|([^0-9A-Za-z \t])|(\w+:\/\/\S+)"," ",x)
dataset["tweets"] = dataset.tweets.map(remove_rt).map(rt)
dataset["tweets"] = dataset.tweets.str.lower()
dataset.head(10)

import nltk
nltk.download('vader_lexicon')

total_pos=len(dataset.loc[dataset['sentiment'] == "positive"])
total_neg=len(dataset.loc[dataset['sentiment'] == "negative"])
total_neu=len(dataset.loc[dataset['sentiment'] == "neutral"])
total_tweets=len(dataset)
print("Total Positive Tweets % : {:.2f}".format( (total_pos/total_tweets)*100))
print("Total Negative Tweets % : {:.2f}".format((total_neg/total_tweets)*100))
print("Total Neutral Tweets % : {:.2f}".format((total_neu/total_tweets)*100))

import matplotlib.pyplot as plt
mylabels = ["Positive", "Negative", "Neutral"]
mycolors = ["Green", "Red", "Blue"]
plt.figure(figsize=(1,1), dpi = 200)
myexplode = [0, 0, 0]
plt.pie([total_pos,total_neg,total_neu],colors=mycolors,labels=mylabels,explode = myexplode)
plt.show()

tweet_list=pd.DataFrame(dataset['tweets'])
tweet_list

def remove_punct(text):
    text  = "".join([char for char in text if char not in string.punctuation])
    text = re.sub('[0-9]+', '', text)
    return text

tweet_list['punct'] = tweet_list['tweets'].apply(lambda x: remove_punct(x))

def tokenization(text):
    text = re.split('\W+', text)
    return text

tweet_list['tokenized'] = tweet_list['punct'].apply(lambda x: tokenization(x.lower()))

nltk.download('stopwords')

stopword = nltk.corpus.stopwords.words('english')
def remove_stopwords(text):
    text = [word for word in text if word not in stopword]
    return text

tweet_list['nonstop'] = tweet_list['tokenized'].apply(lambda x: remove_stopwords(x))
word_tokens = tweet_list["nonstop"]
print(word_tokens)

print(tweet_list.head())

#pip install nltk

ps = nltk.PorterStemmer()

def stemming(text):
    text = [ps.stem(word) for word in text]
    return text

tweet_list['stemmed'] = tweet_list['nonstop'].apply(lambda x: stemming(x))

nltk.download('wordnet')
from nltk.stem import WordNetLemmatizer
wnl = WordNetLemmatizer()
def lemmatizing(text):
  text = ' '.join([wnl.lemmatize(words) for words in text])
  return text
tweet_list['lemmatized'] = tweet_list['stemmed'].apply(lambda x: stemming(x))
print(tweet_list['lemmatized'])

def clean_text(text):
    text_lc = "".join([word.lower() for word in text if word not in string.punctuation]) # remove puntuation
    text_rc = re.sub('[0-9]+', '', text_lc)
    tokens = re.split('\W+', text_rc)    # tokenization
    text = [ps.stem(word) for word in tokens if word not in stopword]  # remove stopwords and stemming
    return text

import nltk
nltk.download('omw-1.4')

"""**Final Data frame with clean text**"""

#print(word_tokens)
final_df = pd.DataFrame(word_tokens,columns=['text'])
final_df['text'] = tweet_list['lemmatized']
final_df['target'] = dataset['sentiment']
X = final_df.text # get all the text in x variable
y = final_df.target
print(X,y)
print(X.shape,y.shape)
final_df['text']= final_df['text'].str.join(" ")
final_df.head()

final_df["text"]= final_df["text"].str.join("")
final_df.head()

nltk.download('stopwords')
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer (max_features=2500, min_df=7, max_df=0.8, stop_words=stopwords.words('english'))
tfidf = vectorizer.fit_transform(final_df['text']).toarray()
print(tfidf)

labels = final_df.iloc[:, 1].values
labels

from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(tfidf,labels, test_size=0.2, random_state=0)
X = tfidf
Y = labels

countVectorizer = CountVectorizer(analyzer=clean_text)
countVector = countVectorizer.fit_transform(tweet_list['lemmatized'])

"""KNN"""

from sklearn.neighbors import KNeighborsClassifier
model = KNeighborsClassifier()
model.fit(X_train,Y_train)
Y_predict = model.predict(X_test)
print(Y_predict)
pred_prob1 = model.predict_proba(X_test)
Y_test

from sklearn.metrics import confusion_matrix
print(confusion_matrix(Y_test, Y_predict))

from sklearn.metrics import classification_report
print(classification_report(Y_test, Y_predict))

"""accuracy score for KNN"""

from sklearn.metrics import accuracy_score
print(accuracy_score(Y_test,Y_predict))
pd.crosstab(Y_test,Y_predict)

"""F1 score, recall score for KNN"""

from sklearn.metrics import f1_score
print(f1_score(Y_test, Y_predict, average='micro'))
from sklearn.metrics import recall_score
print(recall_score(Y_test, Y_predict, average='micro'))

"""Precision score for KNN"""

from sklearn.metrics import precision_score
print(precision_score(Y_test, Y_predict, average='micro'))

"""Decision Tree"""

from sklearn.tree import DecisionTreeClassifier
model = DecisionTreeClassifier()
model.fit(X_train,Y_train)
Y_predict = model.predict(X_test)
print("Y_predict is: ",Y_predict)
print("Y_test is: ",Y_test)

from sklearn.metrics import confusion_matrix
print(confusion_matrix(Y_test, Y_predict))

from sklearn.metrics import classification_report
print(classification_report(Y_test, Y_predict))

"""Accuracy score for Decision Tree"""

from sklearn.metrics import accuracy_score
print(accuracy_score(Y_test,Y_predict))
pd.crosstab(Y_test,Y_predict)

"""Precision score for Decision Tree"""

from sklearn.metrics import precision_score
print(precision_score(Y_test, Y_predict, average='micro'))

"""Recall and F1 score for Decision Tree"""

from sklearn.metrics import f1_score
print(f1_score(Y_test, Y_predict, average='micro'))
from sklearn.metrics import recall_score
print(recall_score(Y_test, Y_predict, average='weighted'))

"""Naive Bayes"""

from sklearn.naive_bayes import GaussianNB
model=GaussianNB()
model.fit(X_train,Y_train)
Y_predict = model.predict(X_test)
Y_predict
Y_test

from sklearn.metrics import confusion_matrix
print(confusion_matrix(Y_test, Y_predict))

from sklearn.metrics import classification_report
print(classification_report(Y_test, Y_predict))

"""Accuracy score for Naive Bayes"""

from sklearn.metrics import accuracy_score
print(accuracy_score(Y_test,Y_predict))
pd.crosstab(Y_test,Y_predict)

"""Precision score for Naive Bayes"""

from sklearn.metrics import precision_score
print(precision_score(Y_test, Y_predict, average='micro'))

"""Recall, F1 score for Naive Bayes"""

from sklearn.metrics import f1_score
print(f1_score(Y_test, Y_predict, average='micro'))
from sklearn.metrics import recall_score
print(recall_score(Y_test, Y_predict, average='weighted'))

"""**ANN**"""

from sklearn.neural_network import MLPClassifier
model = MLPClassifier(solver='lbfgs',alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1)
model.fit(X_train,Y_train)
Y_predict = model.predict(X_test)
Y_predict

from sklearn.metrics import confusion_matrix
print(confusion_matrix(Y_test, Y_predict))

from sklearn.metrics import classification_report
print(classification_report(Y_test, Y_predict))

"""Accuracy score for ann"""

from sklearn.metrics import accuracy_score
print(accuracy_score(Y_test,Y_predict))
pd.crosstab(Y_test,Y_predict)

"""Precision score for ANN"""

from sklearn.metrics import precision_score
print(precision_score(Y_test, Y_predict, average='micro'))

"""Recall, F1 score for ANN"""

from sklearn.metrics import f1_score
print(f1_score(Y_test, Y_predict, average='micro'))
from sklearn.metrics import recall_score
print(recall_score(Y_test, Y_predict, average='weighted'))

"""**Random Forest**"""

from sklearn.ensemble import RandomForestClassifier
rf_clf = RandomForestClassifier(criterion='entropy')
rf_clf.fit(X_train,Y_train)

"""Accuracy score for random forest"""

y_predict = rf_clf.predict(X_test)
from sklearn.metrics import accuracy_score,classification_report,confusion_matrix
print(accuracy_score(Y_test,y_predict))

"""Precision score for random forest"""

from sklearn.metrics import precision_score
print(precision_score(Y_test, Y_predict, average='micro'))

"""Recall, f1 score for random forest"""

from sklearn.metrics import f1_score
print(f1_score(Y_test, Y_predict, average='micro'))
from sklearn.metrics import recall_score
print(recall_score(Y_test, Y_predict, average='weighted'))

